{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nilearn\n",
      "  Obtaining dependency information for nilearn from https://files.pythonhosted.org/packages/d3/6d/f9e6f3e38bf6d8d2986c6a426f69f3b45191367383494a515f45dd748692/nilearn-0.10.2-py3-none-any.whl.metadata\n",
      "  Downloading nilearn-0.10.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from nilearn) (1.2.0)\n",
      "Collecting lxml (from nilearn)\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/50/ba/cb7bc9728a3be4e00dfd658fc76dc64fd9dbc3d5492ff44cda70574329c6/lxml-4.9.3-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading lxml-4.9.3-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting nibabel>=3.2.0 (from nilearn)\n",
      "  Downloading nibabel-5.1.0-py3-none-any.whl (3.3 MB)\n",
      "     ---------------------------------------- 0.0/3.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.3 MB 435.7 kB/s eta 0:00:08\n",
      "      --------------------------------------- 0.1/3.3 MB 491.5 kB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.1/3.3 MB 476.3 kB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.1/3.3 MB 552.2 kB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.1/3.3 MB 532.5 kB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.2/3.3 MB 653.6 kB/s eta 0:00:05\n",
      "     --- ------------------------------------ 0.3/3.3 MB 655.4 kB/s eta 0:00:05\n",
      "     --- ------------------------------------ 0.3/3.3 MB 655.2 kB/s eta 0:00:05\n",
      "     --- ------------------------------------ 0.3/3.3 MB 633.2 kB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 0.3/3.3 MB 635.0 kB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 0.4/3.3 MB 618.4 kB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 0.4/3.3 MB 606.2 kB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 0.5/3.3 MB 655.2 kB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 0.5/3.3 MB 684.7 kB/s eta 0:00:05\n",
      "     ------ --------------------------------- 0.5/3.3 MB 695.1 kB/s eta 0:00:04\n",
      "     ------ --------------------------------- 0.6/3.3 MB 720.2 kB/s eta 0:00:04\n",
      "     ------- -------------------------------- 0.6/3.3 MB 752.2 kB/s eta 0:00:04\n",
      "     -------- ------------------------------- 0.7/3.3 MB 733.8 kB/s eta 0:00:04\n",
      "     --------- ------------------------------ 0.7/3.3 MB 772.8 kB/s eta 0:00:04\n",
      "     --------- ------------------------------ 0.8/3.3 MB 778.2 kB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 0.8/3.3 MB 803.7 kB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 0.9/3.3 MB 805.0 kB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 1.0/3.3 MB 825.7 kB/s eta 0:00:03\n",
      "     ------------ --------------------------- 1.0/3.3 MB 853.3 kB/s eta 0:00:03\n",
      "     ------------- -------------------------- 1.1/3.3 MB 882.0 kB/s eta 0:00:03\n",
      "     ------------- -------------------------- 1.1/3.3 MB 897.8 kB/s eta 0:00:03\n",
      "     --------------- ------------------------ 1.3/3.3 MB 937.1 kB/s eta 0:00:03\n",
      "     --------------- ------------------------ 1.3/3.3 MB 933.6 kB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 1.4/3.3 MB 929.6 kB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 1.4/3.3 MB 965.4 kB/s eta 0:00:02\n",
      "     ------------------ --------------------- 1.5/3.3 MB 982.7 kB/s eta 0:00:02\n",
      "     ------------------- -------------------- 1.6/3.3 MB 1.0 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 1.7/3.3 MB 1.0 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 1.9/3.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 1.9/3.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 2.0/3.3 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 2.1/3.3 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 2.2/3.3 MB 1.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 2.2/3.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 2.4/3.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 2.4/3.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 2.5/3.3 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 2.5/3.3 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 2.6/3.3 MB 1.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 2.7/3.3 MB 1.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 2.8/3.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 2.9/3.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 2.9/3.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 3.0/3.3 MB 1.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 3.1/3.3 MB 1.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 3.2/3.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.2/3.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.3/3.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.3/3.3 MB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from nilearn) (1.24.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from nilearn) (23.1)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from nilearn) (2.0.2)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from nilearn) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from nilearn) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from nilearn) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.5->nilearn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.5->nilearn) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from requests>=2.25.0->nilearn) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from requests>=2.25.0->nilearn) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from requests>=2.25.0->nilearn) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from requests>=2.25.0->nilearn) (2023.5.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=1.0.0->nilearn) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vasan\\downloads\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->nilearn) (1.16.0)\n",
      "Downloading nilearn-0.10.2-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/10.4 MB 2.0 MB/s eta 0:00:06\n",
      "    --------------------------------------- 0.2/10.4 MB 1.8 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.3/10.4 MB 2.1 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/10.4 MB 2.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.5/10.4 MB 2.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/10.4 MB 2.0 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.8/10.4 MB 2.2 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.8/10.4 MB 2.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.0/10.4 MB 2.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.1/10.4 MB 2.0 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.1/10.4 MB 1.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.2/10.4 MB 1.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.3/10.4 MB 1.8 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.3/10.4 MB 1.8 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.4/10.4 MB 1.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.5/10.4 MB 1.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.6/10.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/10.4 MB 1.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/10.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.9/10.4 MB 1.8 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.1/10.4 MB 1.9 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.2/10.4 MB 1.9 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.3/10.4 MB 1.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.4/10.4 MB 1.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.5/10.4 MB 1.9 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.6/10.4 MB 1.9 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.6/10.4 MB 1.9 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.6/10.4 MB 1.9 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.7/10.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.8/10.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.9/10.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.9/10.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.0/10.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.1/10.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.2/10.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.3/10.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.4/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.4/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.5/10.4 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.6/10.4 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.7/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.8/10.4 MB 1.7 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.9/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.0/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.2/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.2/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.3/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.4/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.5/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.6/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.7/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.8/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.9/10.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.0/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.1/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.2/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.3/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.4/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.4/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.5/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.6/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.7/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.7/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.8/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.9/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.0/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.1/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.2/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.4/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.5/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.6/10.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.7/10.4 MB 1.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.9/10.4 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.0/10.4 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.1/10.4 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.3/10.4 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.4/10.4 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.5/10.4 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.6/10.4 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.7/10.4 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.8/10.4 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.9/10.4 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.1/10.4 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.2/10.4 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.3/10.4 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.4/10.4 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.6/10.4 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.7/10.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.8/10.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.9/10.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.0/10.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.2/10.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.3/10.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.5/10.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.6/10.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.7/10.4 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.9/10.4 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.1/10.4 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.4 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.4 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.4 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.4/10.4 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading lxml-4.9.3-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/3.8 MB 3.6 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.2/3.8 MB 2.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.3/3.8 MB 2.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.4/3.8 MB 2.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.6/3.8 MB 2.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.8/3.8 MB 2.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.9/3.8 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.1/3.8 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.2/3.8 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.4/3.8 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.7/3.8 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.8/3.8 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.0/3.8 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.1/3.8 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.2/3.8 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.3/3.8 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.5/3.8 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.6/3.8 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.9/3.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.0/3.8 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.1/3.8 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.2/3.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.3/3.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.4/3.8 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.4/3.8 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.6/3.8 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.7/3.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: nibabel, lxml, nilearn\n",
      "Successfully installed lxml-4.9.3 nibabel-5.1.0 nilearn-0.10.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system(u'pip install nilearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vasan\\Downloads\\Programs\\Python\\Python310\\lib\\site-packages\\nilearn\\input_data\\__init__.py:23: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\vasan\\Downloads\\Programs\\Python\\Python310\\lib\\site-packages\\nilearn\\datasets\\struct.py:688: UserWarning: Only 403 subjects are available in the DARTEL-normalized version of the dataset. All of them will be used instead of the wanted 416\n",
      "  warnings.warn(\n",
      "c:\\Users\\vasan\\Downloads\\Programs\\Python\\Python310\\lib\\site-packages\\nilearn\\datasets\\struct.py:852: UserWarning: `legacy_format` will default to `False` in release 0.11. Dataset fetchers will then return pandas dataframes by default instead of recarrays.\n",
      "  warnings.warn(_LEGACY_FORMAT_MSG)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "from nilearn.image import smooth_img\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "\n",
    "n_subjects = 416\n",
    "\n",
    "oasis_dataset = datasets.fetch_oasis_vbm(n_subjects=n_subjects)\n",
    "gray_matter_map_filenames = oasis_dataset.gray_matter_maps\n",
    "gm_imgs = gray_matter_map_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr = oasis_dataset.ext_vars['cdr'].astype(float)\n",
    "cdr_numpy_arr = np.array(cdr)\n",
    "for i in range(len(cdr_numpy_arr)):\n",
    "    if(np.isnan(cdr_numpy_arr[i])): \n",
    "        cdr_numpy_arr[i] = 1\n",
    "    elif(cdr_numpy_arr[i] > 0.0):\n",
    "        cdr_numpy_arr[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgArr = []\n",
    "\n",
    "for imgUrl in gray_matter_map_filenames:\n",
    "    result_img = smooth_img(imgUrl, fwhm=1)\n",
    "    imgArr.append(result_img.get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "rshapedImgArr = []\n",
    "\n",
    "for img in imgArr:\n",
    "    newImg = [cv2.resize(each_slice,(50,50)) for each_slice in img]#Reducing slice count\n",
    "    newImg = np.array(newImg)\n",
    "    rshapedImgArr.append(newImg)\n",
    "    \n",
    "label = cdr_numpy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = keras.utils.to_categorical(cdr_numpy_arr, 2)\n",
    "\n",
    "much_data = []\n",
    "\n",
    "for num, img in enumerate(rshapedImgArr):\n",
    "    much_data.append([img,label[num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE_PX_X = 50\n",
    "IMG_SIZE_PX_Y = 50\n",
    "SLICE_COUNT = 91\n",
    "\n",
    "n_classes = 2\n",
    "batch_size = 10\n",
    "\n",
    "x = tf.placeholder('float')\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "keep_rate = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3d(x, W):\n",
    "    conv = tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\n",
    "    conv = tf.nn.dropout(conv, 0.5)\n",
    "    return conv\n",
    "\n",
    "def maxpool3d(x):\n",
    "    #                        size of window         movement of window as you slide about\n",
    "    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_neural_network(x):\n",
    "    #                # 5 x 5 x 5 patches, 1 channel, 32 features to compute.\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,3,1,32])),\n",
    "                #       5 x 5 x 5 patches, 32 channels, 64 features to compute.\n",
    "                'W_conv2':tf.Variable(tf.random_normal([3,3,3,32,64])),\n",
    "                #                                  64 features\n",
    "                'W_fc':tf.Variable(tf.random_normal([248768,1024])),\n",
    "                'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "                'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "                'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "                'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    #                            image X      image Y        image Z\n",
    "    x = tf.reshape(x, shape=[-1, IMG_SIZE_PX_X, IMG_SIZE_PX_Y, SLICE_COUNT, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool3d(conv1)\n",
    "\n",
    "\n",
    "    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool3d(conv2)\n",
    "\n",
    "    fc = tf.reshape(conv2,[-1, 248768])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, keep_rate)\n",
    "\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = much_data[:-333]\n",
    "# validation_data = much_data[-83:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = convolutional_neural_network(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    \n",
    "    file = open(\"Output.txt\", \"w\")\n",
    "    \n",
    "    # hm_epochs = 1000\n",
    "    hm_epochs = 50\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "        successful_runs = 0\n",
    "        total_runs = 0\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            train_data, validation_data = train_test_split(much_data, train_size=0.8)\n",
    "            \n",
    "            for data in train_data:\n",
    "                total_runs += 1\n",
    "                try:\n",
    "                    X = data[0]\n",
    "                    Y = data[1]\n",
    "                    _, c = sess.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
    "                    epoch_loss += c\n",
    "                    successful_runs += 1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                    #print(str(e))\n",
    "            \n",
    "            print(f\"Epoch {epoch+1} completed out of {hm_epochs} loss : {epoch_loss}\")\n",
    "            file.write(f\"Epoch {epoch+1} completed out of {hm_epochs} loss : {epoch_loss}\")\n",
    "\n",
    "            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "\n",
    "            print(f\"Accuracy : {accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]})}\")\n",
    "            file.write(f\"Accuracy : {accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]})}\")\n",
    "            \n",
    "            save_path = saver.save(sess, \"model.ckpt\")\n",
    "            print(f\"Model saved in file: {save_path}\")\n",
    "\n",
    "        print('Done. Finishing accuracy : ')\n",
    "        print(f\"Accuracy : {accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]})}\")\n",
    "        \n",
    "        print(f\"fitment percent : {successful_runs/total_runs}\")\n",
    "        \n",
    "        file.write(f\"Done. Finishing accuracy : \")\n",
    "        file.write(f\"Accuracy : {accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]})}\")\n",
    "        \n",
    "        file.write(f\"fitment percent : {successful_runs/total_runs}\")\n",
    "\n",
    "        save_path = saver.save(sess, \"model.ckpt\")\n",
    "        print(f\"Final model saved in file : {save_path}\")\n",
    "\n",
    "train_neural_network(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
